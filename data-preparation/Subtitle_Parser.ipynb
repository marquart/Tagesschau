{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36fce3c9-8a62-4faf-8fd3-c6c5307380e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99cbfe9-733f-48fb-b7c3-02ffaf6559f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extractDescConfig(page):\n",
    "    '''Extract the description and the config json from the page\n",
    "    :param page: The web page\n",
    "    :type page: bs4.BeautifulSoup\n",
    "    :return: The description and the parsed config json\n",
    "    :rtype: string, dict\n",
    "    \n",
    "    Reused Code From\n",
    "    https://github.com/alexmerkel/tsarchiver/blob/main/subconvert.py\n",
    "    '''\n",
    "    #Extract description\n",
    "    desc = page.body.find(\"div\", attrs={\"class\" : \"copytext__video__details\"}).find('p').text.strip()\n",
    "    #Extract config\n",
    "    config = page.body.find(\"div\", attrs={\"class\" : \"ts-mediaplayer\"})[\"data-config\"]\n",
    "    config = json.loads(config)\n",
    "    return desc, config\n",
    "\n",
    "def generateStringFromRawSubs(subtitles):\n",
    "\n",
    "    '''\n",
    "    Reused Code From\n",
    "    subconverter - convert subtitles to the SRT format\n",
    "    https://github.com/alexmerkel/tsarchiver/blob/main/subconvert.py\n",
    "    '''\n",
    "    lines = []\n",
    "    base = BeautifulSoup(subtitles, \"html.parser\")\n",
    "    div = base.find(\"tt:div\")\n",
    "    p = \"tt:p\"\n",
    "    if not div:\n",
    "        div = base.find(\"div\")\n",
    "        p = \"p\"\n",
    "    for p in div.find_all(p):\n",
    "        #Loop through items inside p\n",
    "        par = []\n",
    "        for item in p.findChildren():\n",
    "            #span element: text\n",
    "            if \"span\" in item.name: par.append(item.text)\n",
    "            #br: insert line break\n",
    "            elif \"br\" in item.name: par.append(\"\\n\")\n",
    "        if par: lines.append(''.join(par))\n",
    "    return \"\\n\\n\".join(lines)\n",
    "\n",
    "\n",
    "def getTranscript(config):\n",
    "    # Finde und parse Untertitel\n",
    "    global b\n",
    "    try:\n",
    "        subtitleURL = config[\"mc\"][\"_subtitleUrl\"]\n",
    "    except KeyError:\n",
    "        return \"\"\n",
    "    if not subtitleURL.startswith(\"http\"):\n",
    "        subtitleURL = \"https://www.tagesschau.de\" + subtitleURL\n",
    "    r = requests.get(subtitleURL)\n",
    "    r.raise_for_status()\n",
    "    rawSubs = r.text\n",
    "    transcript = generateStringFromRawSubs(rawSubs)\n",
    "    sleep(3)\n",
    "    return transcript\n",
    "\n",
    "def loadPage(tagesschauURL):\n",
    "    # lade und parse tagesschauURL\n",
    "    r = requests.get(tagesschauURL, allow_redirects=False)\n",
    "    if r.status_code != 200: return None\n",
    "    return BeautifulSoup(r.text, features=\"html.parser\")\n",
    "\n",
    "def extractDate(config):\n",
    "    # Finde Datum der Tagesschau in config des Videos\n",
    "    try:\n",
    "        datetime = config[\"mc\"][\"_info\"][\"clipDate\"]\n",
    "    except KeyError:\n",
    "        return None\n",
    "    match = re.search(\"(\\d?\\d\\.\\d?\\d\\.\\d\\d\\d\\d)\", datetime)\n",
    "    if match: return match.group(1).replace('.','-')\n",
    "    return None\n",
    "\n",
    "def extractDateTranscript(transcript):\n",
    "    # Finde Datum der Tagesschau in Untertiteln\n",
    "    if transcript:\n",
    "        match =  re.search(\"\\((\\d?\\d\\.\\d?\\d\\.\\d\\d\\d\\d)\\)\", transcript)\n",
    "        if match: return match.group(1).replace('.','-')\n",
    "    return None\n",
    "    \n",
    "def processTagesschau(tagesschauURL):\n",
    "    # Finde Untertitel und Beschreibung in tagesschauURL\n",
    "    page = loadPage(tagesschauURL)\n",
    "    if not page or not page.title or '20:00' not in  page.title.text: return None\n",
    "    desc, config = extractDescConfig(page)\n",
    "    transcript = getTranscript(config)\n",
    "    date = extractDateTranscript(transcript)\n",
    "    if not date: date = extractDate(config)\n",
    "    \n",
    "    if desc and transcript and date: return {'topics':desc, 'date':date, 'transcript':transcript}\n",
    "    return {}\n",
    "\n",
    "def saveTagesschau(info):\n",
    "    # speichere Untertitel-Text der Tagesschau\n",
    "    if not info: return False\n",
    "    with open(f\"./Data/Tagesschau_{info['date']}.json\", 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump(info, f, ensure_ascii=False)\n",
    "    return True\n",
    "\n",
    "def runProcess(start, end):\n",
    "    # crawl the Tagesschau Sendungs-Archiv, beginning at ID=start, end at ID=end\n",
    "    successCount = 0\n",
    "    for i in range(start, end+1):\n",
    "        tagesschauURL = f\"https://www.tagesschau.de/multimedia/sendung/ts-{i}.html\"\n",
    "        info = processTagesschau(tagesschauURL)\n",
    "        if info:\n",
    "            info['index'] = i\n",
    "            success = saveTagesschau(info)\n",
    "            if success:\n",
    "                successCount += 1\n",
    "                print(f\"Saved Tagesschau {info['date']} ({tagesschauURL}), {successCount} completed\")\n",
    "            else: print(f\"Couldn't save Tagesschau ({tagesschauURL})\")\n",
    "        else:\n",
    "            print(f\"    Tagesschau not found ({tagesschauURL})\")\n",
    "        sleep(2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1efda-09b2-4a2c-9e78-e357236f228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runProcess(132, 241)\n",
    "#runProcess(242, 43133)\n",
    "#runProcess(3004, 43133)\n",
    "#runProcess(3297, 43133)\n",
    "#runProcess(3384, 43133)\n",
    "#runProcess(3776, 43133)https://www.tagesschau.de/multimedia/sendung/ts-42307.html\n",
    "#runProcess(42307, 43133)\n",
    "#runProcess(9689, 42293)\n",
    "#runProcess(14919, 42293)\n",
    "#runProcess(18105, 42293)\n",
    "#runProcess(20399, 42293)\n",
    "#runProcess(21567, 42293)\n",
    "#runProcess(22545, 42293)\n",
    "#runProcess(23011, 42293)\n",
    "#runProcess(24001, 42293)\n",
    "#runProcess(28877, 28877)https://www.tagesschau.de/multimedia/sendung/ts-33221.html\n",
    "#runProcess(29323, 42293)\n",
    "#runProcess(33221, 42293)\n",
    "#runProcess(35883, 42293)\n",
    "#runProcess(36219, 42293)\n",
    "#runProcess(37097, 42293)\n",
    "#runProcess(40511, 42293)\n",
    "#runProcess(43191, 43623)\n",
    "runProcess(43207, 43623)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d303f-e09a-4d46-9240-e9f69b4a7983",
   "metadata": {},
   "source": [
    "# Evaluate completeness & visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb51283-6299-4bd0-8903-daf828f0f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c092ce5-742b-47ac-b99c-2964d7ab8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3db3685a-b956-473b-a6f4-813f9aa0cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 26\n",
    "plt.rcParams[\"font.family\"] = 'PT Sans','Noto Sans', 'Noto Serif'\n",
    "plt.rcParams[\"xtick.labelsize\"] = fontsize*0.8\n",
    "plt.rcParams[\"ytick.labelsize\"] = fontsize\n",
    "plt.rcParams[\"legend.fontsize\"] = fontsize\n",
    "plt.rcParams[\"ytick.major.pad\"] = 10\n",
    "plt.rcParams[\"xtick.major.pad\"] = 10\n",
    "plt.rcParams[\"ytick.major.width\"] = 0\n",
    "plt.rcParams[\"xtick.bottom\"] = True\n",
    "plt.rcParams[\"xtick.color\"] = 'white'\n",
    "plt.rcParams[\"xtick.major.width\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1d0f2f-4b14-4834-80ef-4a8db57c042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dates = set()\n",
    "\n",
    "DATE_PATTERN = re.compile(\"Tagesschau_(.*).json\")\n",
    "for file in os.listdir(\"./Data/\"):\n",
    "    if file.endswith('.json'):\n",
    "        match = DATE_PATTERN.search(file)\n",
    "        if match: parsed_dates.add(match.group(1))\n",
    "        else: print(f\"Date not found in file name: {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb4a597-447a-437c-a500-19dc673282f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da678091-3994-4409-8755-d86ec422db9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success = 2408, failed = 149, of 2557\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBIAAAB9CAYAAAAftUBaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAADXElEQVR4nO3bMQqDQBBAUQ1exfsfx8KTCMKmDyl+mizCe+0UM/WHWccYYwEAAAAIXrMPAAAAAJ5DSAAAAAAyIQEAAADIhAQAAAAgExIAAACATEgAAAAAsqkh4TzPmesBAACAH00NCfd9z1wPAAAA/MhrAwAAAJAJCQAAAEAmJAAAAACZkAAAAABkQgIAAACQCQkAAABAJiQAAAAAmZAAAAAAZEICAAAAkAkJAAAAQCYkAAAAAJmQAAAAAGRCAgAAAJAJCQAAAEAmJAAAAACZkAAAAABkQgIAAACQCQkAAABAJiQAAAAAmZAAAAAAZEICAAAAkAkJAAAAQCYkAAAAAJmQAAAAAGRCAgAAAJAJCQAAAEAmJAAAAACZkAAAAABkQgIAAACQCQkAAABAJiQAAAAAmZAAAAAAZEICAAAAkAkJAAAAQCYkAAAAAJmQAAAAAGRCAgAAAJAJCQAAAEAmJAAAAACZkAAAAABkQgIAAACQCQkAAABAJiQAAAAAmZAAAAAAZEICAAAAkAkJAAAAQCYkAAAAAJmQAAAAAGRCAgAAAJAJCQAAAEAmJAAAAACZkAAAAABk28zl13Utx3HMPAEAAAD4sG3bsu/719k6xhh/vgcAAAB4KK8NAAAAQCYkAAAAAJmQAAAAAGRCAgAAAJAJCQAAAEAmJAAAAACZkAAAAABkQgIAAACQCQkAAABAJiQAAAAAmZAAAAAAZEICAAAAkAkJAAAAQCYkAAAAAJmQAAAAAGRCAgAAAJAJCQAAAEAmJAAAAACZkAAAAABkQgIAAACQCQkAAABAJiQAAAAAmZAAAAAAZEICAAAAkAkJAAAAQCYkAAAAAJmQAAAAAGRCAgAAAJAJCQAAAEAmJAAAAACZkAAAAABkQgIAAACQCQkAAABAJiQAAAAAmZAAAAAAZEICAAAAkAkJAAAAQCYkAAAAAJmQAAAAAGRCAgAAAJAJCQAAAEAmJAAAAACZkAAAAABkQgIAAACQCQkAAABAJiQAAAAAmZAAAAAAZEICAAAAkAkJAAAAQCYkAAAAAJmQAAAAAGRCAgAAAJAJCQAAAEAmJAAAAACZkAAAAABkQgIAAACQCQkAAABAJiQAAAAAmZAAAAAAZEICAAAAkAkJAAAAQCYkAAAAANkbuKkUYztsmwEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1296x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def daterange(start, end):\n",
    "    for n in range(int((end - start).days)+1):\n",
    "        yield start + timedelta(days=n)\n",
    "\n",
    "start = date(2014, 6, 1)\n",
    "end = date(2021, 5, 31)\n",
    "xticks = {}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,1))\n",
    "success, failed = 0, 0\n",
    "for i, dt in enumerate(daterange(start, end)):\n",
    "    if not dt.month % 6 and dt.day == 1: xticks[i] = dt.strftime(\"%b\\n%Y\")\n",
    "    if dt.strftime(\"%d-%m-%Y\") in parsed_dates:\n",
    "        success +=1\n",
    "        ax.bar(i, 1, width=1, color='white', align='edge', linewidth=0)\n",
    "    else:\n",
    "        failed +=1\n",
    "        ax.bar(i, 1, width=1, color='green', align='edge', linewidth=0, alpha=0)\n",
    "        \n",
    "ax.set_xlim(left=0, right=2557)\n",
    "ax.set_ylim(top=1)\n",
    "ax.set_yticklabels(())\n",
    "ax.set_xticks(list(xticks))\n",
    "ax.set_xticklabels([xticks[k] for k in xticks], color='white')\n",
    "sns.despine()\n",
    "ax.grid(False)\n",
    "print(f\"success = {success}, failed = {failed}, of {success+failed}\")\n",
    "\n",
    "plt.savefig(\"Gefundene_Sendungen.png\",dpi=600, bbox_inches='tight', transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ae50c4-6399-4172-824a-a842cd2f49f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9417285881892843"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2408/2557"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-TextViz",
   "language": "python",
   "name": "venv-textviz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
